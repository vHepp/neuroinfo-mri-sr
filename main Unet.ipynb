{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1f9eafd3",
   "metadata": {},
   "source": [
    "## Neuroinformatics Project 1: MRI upscaling\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1672022e",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1371aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, math, time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "from tempfile import TemporaryDirectory\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import nibabel as nib\n",
    "from nilearn import plotting\n",
    "\n",
    "\n",
    "\n",
    "from extract_slices import (\n",
    "    # load_nifti,\n",
    "    slice_to_base64,\n",
    "    base64_to_slice,\n",
    "    volume_to_submission_rows,\n",
    "    create_submission_df,\n",
    "    nifti_to_submission_rows\n",
    ")\n",
    "\n",
    "# import metric\n",
    "from metric_pt2 import compute_ms_ssim\n",
    "# import extract_slices\n",
    "\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "device = \"cpu\"\n",
    "# if torch.backends.mps.is_available():\n",
    "#     device = \"mps\"\n",
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    cudnn.benchmark = True\n",
    "    \n",
    "print(\"device:\", device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    \"SEED\": 42,\n",
    "    \"DEVICE\": \"cuda\" if torch.cuda.is_available() else \"cpu\",\n",
    "    \"BATCH_SIZE\": 2,\n",
    "    \"LR\": 2e-4,\n",
    "    \"WEIGHT_DECAY\": 1e-5,\n",
    "    \"NUM_EPOCHS\":7,\n",
    "    # \"NUM_EPOCHS\":40,\n",
    "    # \"PATIENCE\":5,\n",
    "    \"PATCH_SIZE\": (96, 96, 96),\n",
    "    \"PATHS\": {\n",
    "        \"TRAIN\": \"./train/\",\n",
    "        \"TEST\": \"./test/\",\n",
    "        \"CHECKPOINT\": \"./runs/checkpoint_final\",\n",
    "    },\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "set_seed(CONFIG[\"SEED\"])\n",
    "print(f\"Running on: {CONFIG['DEVICE']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adfa11eb",
   "metadata": {},
   "source": [
    "### normalize mri\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba5df4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numpy(x: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Normalize array to [0, 1] range.\"\"\"\n",
    "    x_min, x_max = x.min(), x.max()\n",
    "    if x_max - x_min > 0:\n",
    "        return (x - x_min) / (x_max - x_min)\n",
    "    return np.zeros_like(x)\n",
    "\n",
    "\n",
    "def normalize_tensor(tensor):\n",
    "    # Emergency Fix: Clip top 1% to prevent intensity squashing\n",
    "    v_min = tensor.min()\n",
    "    v_max = np.percentile(\n",
    "        tensor.cpu().numpy() if torch.is_tensor(tensor) else tensor, 99.5\n",
    "    )\n",
    "    tensor = torch.clamp(tensor, v_min, v_max)\n",
    "    return (tensor - v_min) / (v_max - v_min + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71841ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti(path, normalize=True):\n",
    "    \"\"\"\n",
    "    Load a NIfTI file and return the data array.\n",
    "\n",
    "    Args:\n",
    "        path: Path to .nii.gz file\n",
    "\n",
    "    Returns:\n",
    "        3D numpy array (x, y, z)\n",
    "    \"\"\"\n",
    "    img = nib.load(path).get_fdata()\n",
    "\n",
    "    if normalize:\n",
    "        # print(type(img))\n",
    "        img = normalize_numpy(img)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c46719c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_nifti(img):\n",
    "    \"\"\"\n",
    "    Display a NIfTI file give fdata().\n",
    "\n",
    "    Args:\n",
    "        img: fdata associated with a nifti file\n",
    "    \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.imshow(img[img.shape[0] // 2, :, :].T, cmap=\"gray\", origin=\"lower\")\n",
    "    plt.title(\"Middle Slice\")\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae86723",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PROJECT_DIR = \"N:/OneDrive - Youngstown State University/3. NYU/25-26/Spring 2026/Neuroinformatics/Projects/Project 1\"\n",
    "PROJECT_DIR = \"./\"\n",
    "\n",
    "TRAIN_DIR = os.path.join(PROJECT_DIR, \"train/\")\n",
    "TEST_DIR = os.path.join(PROJECT_DIR, \"test/\")\n",
    "\n",
    "HF_TRAIN = os.path.join(TRAIN_DIR, \"high_field/\")\n",
    "LF_TRAIN = os.path.join(TRAIN_DIR, \"low_field/\")\n",
    "\n",
    "LF_TEST = os.path.join(TEST_DIR, \"low_field/\")\n",
    "\n",
    "TRAIN_GROUND_TRUTH_PATH = os.path.join(PROJECT_DIR, \"train.csv\")\n",
    "\n",
    "# Synthetic dataset\n",
    "\n",
    "SYNTHETIC_HF = os.path.join(PROJECT_DIR, \"simulated_data/HR/\")\n",
    "SYNTHETIC_LF = os.path.join(PROJECT_DIR, \"simulated_data/LR/\")\n",
    "\n",
    "\n",
    "print(HF_TRAIN)\n",
    "print(SYNTHETIC_HF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26432ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth_df = pd.read_csv(TRAIN_GROUND_TRUTH_PATH)\n",
    "\n",
    "ground_truth_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed498a1",
   "metadata": {},
   "source": [
    "## Trial image loading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33711ffa",
   "metadata": {},
   "source": [
    "### Project Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d42e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_nifti_pair(sample_id):\n",
    "\n",
    "    LF_sample_path = os.path.join(LF_TRAIN, f\"{sample_id}_lowfield.nii\")\n",
    "    HF_sample_path = os.path.join(HF_TRAIN, f\"{sample_id}_highfield.nii\")\n",
    "\n",
    "    return {\"lowfield\": LF_sample_path, \"highfield\": HF_sample_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a83c49b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_id = \"sample_001\"\n",
    "\n",
    "sample_path_pair = load_nifti_pair(sample_id)\n",
    "\n",
    "for sample_path in sample_path_pair.items():\n",
    "    volume = load_nifti(sample_path[1])\n",
    "\n",
    "    # volume = normalize_mri(volume)\n",
    "\n",
    "    print(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7cd4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sample_path in sample_path_pair.items():\n",
    "    plotting.plot_img(sample_path[1], title=sample_path[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2508f744",
   "metadata": {},
   "source": [
    "## Trilinear interpolation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac594428",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_input(low_field_path, target_shape=(179, 221, 200)):\n",
    "    # 1. Load the NIfTI file\n",
    "    img_nifti = nib.load(low_field_path)\n",
    "    # print(f\"Low-field shape: {img_nifti.shape}\")   # Should be (112, 138, 40)\n",
    "    img_data = img_nifti.get_fdata()\n",
    "    affine = img_nifti.affine\n",
    "\n",
    "    # 2. Convert to PyTorch tensor [Batch, Channel, H, W, D]\n",
    "    tensor = torch.from_numpy(img_data).float().unsqueeze(0).unsqueeze(0)\n",
    "\n",
    "    # print(f\"Tensor Shape: {tensor.shape}\")\n",
    "\n",
    "    # 3. Upsample to match High-Field dimensions\n",
    "    # 'trilinear' is essential for 3D data to keep it smooth\n",
    "    upsampled = F.interpolate(\n",
    "        tensor, size=target_shape, mode=\"trilinear\", align_corners=True\n",
    "    )\n",
    "\n",
    "    return upsampled.squeeze(0), affine  # Returns [1, 179, 221, 200] and the affine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efb8531",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_trio(path_pair):\n",
    "    # Test it on one file\n",
    "    low_path = list(path_pair.items())[0][1]\n",
    "    high_path = list(path_pair.items())[1][1]\n",
    "\n",
    "    if os.path.exists(low_path) and os.path.exists(high_path):\n",
    "\n",
    "        high_nifti = nib.load(high_path)\n",
    "        target_shape = high_nifti.get_fdata().shape\n",
    "        print(f\"target_shape:{target_shape}\")\n",
    "\n",
    "        processed_tensor, original_affine = prepare_input(low_path, target_shape)\n",
    "\n",
    "        data_array = processed_tensor.detach().cpu().numpy().squeeze()\n",
    "\n",
    "        low_shape = nib.load(low_path).shape\n",
    "        scale_factors = np.array(low_shape) / np.array(data_array.shape)\n",
    "\n",
    "        new_affine = original_affine.copy()\n",
    "        new_affine[:3, :3] = original_affine[:3, :3] * scale_factors\n",
    "\n",
    "        viz_img = nib.Nifti1Image(data_array, new_affine)\n",
    "\n",
    "        # 1. Plot the Upsampled Image first and capture the display object\n",
    "        # (We plot this one first or capture it so we can use its coordinates for the others)\n",
    "        upsampled_display = plotting.plot_img(\n",
    "            viz_img,\n",
    "            title=\"Upsampled Low-Field MRI\",\n",
    "            display_mode=\"ortho\",\n",
    "            colorbar=True,\n",
    "        )\n",
    "\n",
    "        # 2. Extract the automatically selected cut coordinates (x, y, z)\n",
    "        # These are the world coordinates chosen by nilearn for the upsampled image\n",
    "        ref_coords = upsampled_display.cut_coords\n",
    "\n",
    "        # 3. Plot the Target High-Field using the same coordinates\n",
    "        # We pass 'ref_coords' to cut_coords to force the exact same view\n",
    "        plotting.plot_img(\n",
    "            high_nifti,\n",
    "            title=\"Target High-Field\",\n",
    "            display_mode=\"ortho\",\n",
    "            cut_coords=ref_coords,\n",
    "        )\n",
    "\n",
    "        # Optional: You can also sync the original low-field to these coordinates\n",
    "        # for a perfect 3-way comparison:\n",
    "        plotting.plot_img(\n",
    "            low_path,\n",
    "            title=\"Original Low-Field\",\n",
    "            display_mode=\"ortho\",\n",
    "            cut_coords=ref_coords,\n",
    "        )\n",
    "\n",
    "        plotting.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ee8089",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image_trio(sample_path_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "397c792e",
   "metadata": {},
   "source": [
    "## Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf54234",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIPatchDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        low_paths,\n",
    "        high_paths,\n",
    "        patches_per_vol=16,\n",
    "        patch_size=96,\n",
    "        transforms=None,\n",
    "        # target_shape=(179, 221, 200),\n",
    "    ):\n",
    "        self.patches_per_vol = patches_per_vol\n",
    "        self.patch_size = patch_size\n",
    "        self.transforms = transforms\n",
    "        self.data = []\n",
    "\n",
    "        self.target_shape = (1, 1, 1)  # Will overwrite with new target shape\n",
    "\n",
    "        print(\n",
    "            \"Loading entire dataset into RAM... (This takes ~1 min but speeds up training 50x)\"\n",
    "        )\n",
    "\n",
    "        for l_path, h_path in zip(low_paths, high_paths):\n",
    "            # 2. Load High-Field ONCE\n",
    "\n",
    "            fdata = nib.load(h_path).get_fdata()\n",
    "\n",
    "            self.target_shape = fdata.shape\n",
    "            # print(f\"target_shape: {target_shape}\")\n",
    "\n",
    "            high_vol = torch.from_numpy(fdata).float().unsqueeze(0)\n",
    "\n",
    "            # 1. Load and Upsample Low-Field ONCE\n",
    "            # prepare_input should return tensor (C, D, H, W) or (C, H, W, D)\n",
    "            low_vol, _ = prepare_input(l_path, target_shape=self.target_shape)\n",
    "\n",
    "            # 3. Normalize ONCE\n",
    "            low_vol = normalize_tensor(low_vol)\n",
    "            high_vol = normalize_tensor(high_vol)\n",
    "\n",
    "            # Store in list\n",
    "            self.data.append({\"low\": low_vol, \"high\": high_vol})\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) * self.patches_per_vol\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Map the continuous index to a specific volume\n",
    "        vol_idx = idx // self.patches_per_vol\n",
    "\n",
    "        # Retrieve pre-loaded volumes from RAM\n",
    "        low_vol = self.data[vol_idx][\"low\"]\n",
    "        high_vol = self.data[vol_idx][\"high\"]\n",
    "\n",
    "        # Get volume dimensions (C, D, H, W)\n",
    "        _, d, h, w = low_vol.shape\n",
    "\n",
    "        valid_patch_found = False\n",
    "        max_attempts = 50  # Give it more chances to find tissue\n",
    "\n",
    "        # Ensure the patch isn't just empty space\n",
    "        for _ in range(max_attempts):\n",
    "            d_start = np.random.randint(0, d - self.patch_size)\n",
    "            h_start = np.random.randint(0, h - self.patch_size)\n",
    "            w_start = np.random.randint(0, w - self.patch_size)\n",
    "\n",
    "            # Extract Patch\n",
    "            low_patch = low_vol[\n",
    "                :,\n",
    "                d_start : d_start + self.patch_size,\n",
    "                h_start : h_start + self.patch_size,\n",
    "                w_start : w_start + self.patch_size,\n",
    "            ]\n",
    "\n",
    "            # Direct defense against SSIM nan: Ensure sufficient variance and signal\n",
    "            if low_patch.mean() > 0.05 and low_patch.var() > 1e-4:\n",
    "                valid_patch_found = True\n",
    "                break\n",
    "\n",
    "        # FALLBACK: If we somehow failed 50 times, grab the exact center of the volume.\n",
    "        # This guarantees we never pass a pure black patch to the model.\n",
    "        if not valid_patch_found:\n",
    "            d_start = (d - self.patch_size) // 2\n",
    "            h_start = (h - self.patch_size) // 2\n",
    "            w_start = (w - self.patch_size) // 2\n",
    "\n",
    "            low_patch = low_vol[\n",
    "                :,\n",
    "                d_start : d_start + self.patch_size,\n",
    "                h_start : h_start + self.patch_size,\n",
    "                w_start : w_start + self.patch_size,\n",
    "            ]\n",
    "\n",
    "        # Extract the exact same region for the high-field target\n",
    "        high_patch = high_vol[\n",
    "            :,\n",
    "            d_start : d_start + self.patch_size,\n",
    "            h_start : h_start + self.patch_size,\n",
    "            w_start : w_start + self.patch_size,\n",
    "        ]\n",
    "\n",
    "        # Apply MONAI Augmentations (Rotation, Flip, etc.)\n",
    "        if self.transforms:\n",
    "            data_dict = self.transforms({\"low\": low_patch, \"high\": high_patch})\n",
    "            return data_dict[\"low\"], data_dict[\"high\"]\n",
    "\n",
    "        return low_patch, high_patch\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     # Map the continuous index to a specific volume\n",
    "    #     vol_idx = idx // self.patches_per_vol\n",
    "\n",
    "    #     # Retrieve pre-loaded volumes from RAM\n",
    "    #     low_vol = self.data[vol_idx][\"low\"]\n",
    "    #     high_vol = self.data[vol_idx][\"high\"]\n",
    "\n",
    "    #     # Get volume dimensions (C, D, H, W)\n",
    "    #     # Note: Assuming dims are (1, 179, 221, 200) based on your description\n",
    "    #     _, d, h, w = low_vol.shape\n",
    "\n",
    "    #     # Ensure patch fits inside volume\n",
    "    #     # We subtract patch_size so we don't index out of bounds\n",
    "\n",
    "    #     # Inside __getitem__ before Extract Patch\n",
    "    #     # Ensure the patch isn't just empty space\n",
    "    #     for _ in range(10):  # Try 10 times to find a \"brainy\" patch\n",
    "    #         d_start = np.random.randint(0, d - self.patch_size)\n",
    "    #         h_start = np.random.randint(0, h - self.patch_size)\n",
    "    #         w_start = np.random.randint(0, w - self.patch_size)\n",
    "\n",
    "    #         # Extract Patch\n",
    "    #         low_patch = low_vol[\n",
    "    #             :,\n",
    "    #             d_start : d_start + self.patch_size,\n",
    "    #             h_start : h_start + self.patch_size,\n",
    "    #             w_start : w_start + self.patch_size,\n",
    "    #         ]\n",
    "    #         if low_patch.mean() > 0.1:  # Basic threshold for brain tissue\n",
    "    #             break\n",
    "\n",
    "    #     high_patch = high_vol[\n",
    "    #         :,\n",
    "    #         d_start : d_start + self.patch_size,\n",
    "    #         h_start : h_start + self.patch_size,\n",
    "    #         w_start : w_start + self.patch_size,\n",
    "    #     ]\n",
    "\n",
    "    #     # Apply MONAI Augmentations (Rotation, Flip, etc.)\n",
    "    #     if self.transforms:\n",
    "    #         # MONAI usually expects a dict input for MapTransforms\n",
    "    #         data_dict = self.transforms({\"low\": low_patch, \"high\": high_patch})\n",
    "    #         return data_dict[\"low\"], data_dict[\"high\"]\n",
    "\n",
    "    #     return low_patch, high_patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd5bddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Uncomment for Project Data\n",
    "low_field_paths = [os.path.join(LF_TRAIN, p) for p in os.listdir(LF_TRAIN)]\n",
    "high_field_paths = [os.path.join(HF_TRAIN, p) for p in os.listdir(HF_TRAIN)]\n",
    "\n",
    "# test_low_field_paths = [os.path.join(LF_TEST, p) for p in os.listdir(LF_TEST)]\n",
    "\n",
    "## Uncomment for Synthetic Data\n",
    "# low_field_paths = [os.path.join(SYNTHETIC_LF, p) for p in os.listdir(SYNTHETIC_LF)]\n",
    "# high_field_paths = [os.path.join(SYNTHETIC_HF, p) for p in os.listdir(SYNTHETIC_HF)]\n",
    "\n",
    "\n",
    "# print(len(low_field_paths))\n",
    "\n",
    "cap_size = min(18, len(low_field_paths))\n",
    "\n",
    "train_size = min(14, cap_size)\n",
    "val_size = cap_size - train_size\n",
    "\n",
    "\n",
    "from monai.transforms import (\n",
    "    Compose,\n",
    "    RandFlipd,\n",
    "    RandAffined,\n",
    "    RandGaussianNoised,\n",
    "    EnsureTyped,\n",
    ")\n",
    "\n",
    "train_transforms = Compose(\n",
    "    [\n",
    "        # 1. Randomly flip along any axis (Spatial dims 0, 1, 2)\n",
    "        RandFlipd(keys=[\"low\", \"high\"], prob=0.5, spatial_axis=[0, 1, 2]),\n",
    "        # 2. Slight rotations or scaling (optional, but helps generalization)\n",
    "        RandAffined(\n",
    "            keys=[\"low\", \"high\"],\n",
    "            prob=0.2,\n",
    "            rotate_range=(0.1, 0.1, 0.1),\n",
    "            scale_range=(0.1, 0.1, 0.1),\n",
    "            mode=(\"trilinear\", \"trilinear\"),\n",
    "        ),\n",
    "        # 3. Add noise ONLY to the input (low-field) to make model robust\n",
    "        RandGaussianNoised(keys=[\"low\"], prob=0.2, mean=0.0, std=0.01),\n",
    "        EnsureTyped(keys=[\"low\", \"high\"]),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "train_dataset = MRIPatchDataset(\n",
    "    low_field_paths[:train_size],\n",
    "    high_field_paths[:train_size],\n",
    "    transforms=train_transforms,\n",
    ")\n",
    "\n",
    "\n",
    "val_dataset = MRIPatchDataset(\n",
    "    low_field_paths[train_size : train_size + val_size],\n",
    "    high_field_paths[train_size : train_size + val_size],\n",
    ")\n",
    "\n",
    "# test_dataset = MRITestPatchDataset(test_low_field_paths)\n",
    "\n",
    "# SEED = 42\n",
    "# torch.manual_seed(SEED)\n",
    "# g = torch.Generator().manual_seed(SEED)  # Create a reproducible generator\n",
    "\n",
    "# # 4. Perform the random split\n",
    "# train_dataset, val_dataset = random_split(\n",
    "#     full_dataset, [train_size, val_size], generator=g\n",
    "# )\n",
    "\n",
    "\n",
    "# print(train_dataset.low_paths)\n",
    "# print(train_dataset.high_paths)\n",
    "\n",
    "# train_dataset.__getitem__(0)\n",
    "# train_dataset.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc4e109f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    dataset=train_dataset,\n",
    "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
    "    shuffle=True,\n",
    "    # num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset,\n",
    "    batch_size=CONFIG[\"BATCH_SIZE\"],\n",
    "    shuffle=False,\n",
    "    # num_workers=1,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "data_loaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "# test_loader = DataLoader(\n",
    "#     dataset=test_dataset,\n",
    "#     batch_size=1,\n",
    "#     shuffle=False,\n",
    "#     # num_workers=1,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# dataloader = DataLoader(\n",
    "#     dataset=train_dataset,\n",
    "#     batch_size=BATCH_SIZE,\n",
    "#     shuffle=True,\n",
    "#     pin_memory=True,\n",
    "# )\n",
    "\n",
    "# print(f\"Length of full dataset: {len(full_dataset)}\")\n",
    "print(f\"Length of training dataset: {len(train_dataset)} patches\")\n",
    "print(f\"Length of validation dataset: {len(val_dataset)} patches\")\n",
    "# print(f\"Length of test dataset: {len(test_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebbed57",
   "metadata": {},
   "source": [
    "## 3D-UNet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747fd3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "\n",
    "# class UNet3D(nn.Module):\n",
    "#     def __init__(self, in_channels=1, out_channels=1):\n",
    "#         super(UNet3D, self).__init__()\n",
    "\n",
    "#         def conv_block(in_c, out_c):\n",
    "#             return nn.Sequential(\n",
    "#                 nn.Conv3d(in_c, out_c, kernel_size=3, padding=1),\n",
    "#                 nn.BatchNorm3d(out_c),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#                 nn.Conv3d(out_c, out_c, kernel_size=3, padding=1),\n",
    "#                 nn.BatchNorm3d(out_c),\n",
    "#                 nn.ReLU(inplace=True),\n",
    "#             )\n",
    "\n",
    "#         # Encoder\n",
    "#         self.enc1 = conv_block(in_channels, 32)\n",
    "#         self.pool1 = nn.MaxPool3d(2)\n",
    "#         self.enc2 = conv_block(32, 64)\n",
    "#         self.pool2 = nn.MaxPool3d(2)\n",
    "\n",
    "#         # Bottleneck\n",
    "#         self.bottleneck = conv_block(64, 128)\n",
    "\n",
    "#         # Old Decoder\n",
    "#         # self.up2 = nn.ConvTranspose3d(128, 64, kernel_size=2, stride=2)\n",
    "#         # self.dec2 = conv_block(128, 64)\n",
    "#         # self.up1 = nn.ConvTranspose3d(64, 32, kernel_size=2, stride=2)\n",
    "#         # self.dec1 = conv_block(64, 32)\n",
    "\n",
    "#         # Decoder - Replaced ConvTranspose with Upsample + Conv\n",
    "#         self.up_conv2 = nn.Conv3d(128, 64, kernel_size=1)\n",
    "#         self.dec2 = conv_block(128, 64)\n",
    "\n",
    "#         self.up_conv1 = nn.Conv3d(64, 32, kernel_size=1)\n",
    "#         self.dec1 = conv_block(64, 32)\n",
    "\n",
    "#         self.final = nn.Conv3d(32, out_channels, kernel_size=1)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Encoder\n",
    "#         e1 = self.enc1(x)\n",
    "#         e2 = self.enc2(self.pool1(e1))\n",
    "\n",
    "#         # Bottleneck\n",
    "#         b = self.bottleneck(self.pool2(e2))\n",
    "\n",
    "#         # # Decoder with skip connections\n",
    "#         # d2 = self.up2(b)\n",
    "#         # # Handle potential padding issues for non-power-of-2 shapes\n",
    "#         # d2 = torch.cat([d2, e2], dim=1)\n",
    "#         # d2 = self.dec2(d2)\n",
    "\n",
    "#         # d1 = self.up1(d2)\n",
    "#         # d1 = torch.cat([d1, e1], dim=1)\n",
    "#         # d1 = self.dec1(d1)\n",
    "\n",
    "#         # Decoder 2: Trilinear Upsampling + 1x1 Conv to adjust channels\n",
    "#         d2 = F.interpolate(b, scale_factor=2, mode=\"trilinear\", align_corners=True)\n",
    "#         d2 = self.up_conv2(d2)\n",
    "#         d2 = torch.cat([d2, e2], dim=1)\n",
    "#         d2 = self.dec2(d2)\n",
    "\n",
    "#         # Decoder 1\n",
    "#         d1 = F.interpolate(d2, scale_factor=2, mode=\"trilinear\", align_corners=True)\n",
    "#         d1 = self.up_conv1(d1)\n",
    "#         d1 = torch.cat([d1, e1], dim=1)\n",
    "#         d1 = self.dec1(d1)\n",
    "\n",
    "#         return self.final(d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b882f5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ResConvBlock3D(nn.Module):\n",
    "    \"\"\"A Residual Convolutional Block for 3D data.\"\"\"\n",
    "\n",
    "    def __init__(self, in_c, out_c):\n",
    "        super().__init__()\n",
    "        # If in_c != out_c, we need a 1x1 conv to match dimensions for the skip connection\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if in_c != out_c:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv3d(in_c, out_c, kernel_size=1, bias=False),\n",
    "                nn.InstanceNorm3d(out_c),\n",
    "            )\n",
    "\n",
    "        self.conv1 = nn.Conv3d(in_c, out_c, kernel_size=3, padding=1, bias=False)\n",
    "        self.norm1 = nn.InstanceNorm3d(out_c)\n",
    "        self.relu = nn.LeakyReLU(0.2, inplace=True)\n",
    "\n",
    "        self.conv2 = nn.Conv3d(out_c, out_c, kernel_size=3, padding=1, bias=False)\n",
    "        self.norm2 = nn.InstanceNorm3d(out_c)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = self.shortcut(x)\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.norm1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.norm2(out)\n",
    "\n",
    "        out += residual  # Add the residual connection\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class BetterUNet3D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=1):\n",
    "        super().__init__()\n",
    "\n",
    "        # Encoder (Deeper: 4 levels now)\n",
    "        self.enc1 = ResConvBlock3D(in_channels, 32)\n",
    "        self.pool1 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.enc2 = ResConvBlock3D(32, 64)\n",
    "        self.pool2 = nn.MaxPool3d(2)\n",
    "\n",
    "        self.enc3 = ResConvBlock3D(64, 128)\n",
    "        self.pool3 = nn.MaxPool3d(2)\n",
    "\n",
    "        # Bottleneck\n",
    "        self.bottleneck = ResConvBlock3D(128, 256)\n",
    "\n",
    "        # Decoder 3\n",
    "        self.up_conv3 = nn.Conv3d(256, 128, kernel_size=1)\n",
    "        self.dec3 = ResConvBlock3D(256, 128)  # 256 because 128 (up) + 128 (skip)\n",
    "\n",
    "        # Decoder 2\n",
    "        self.up_conv2 = nn.Conv3d(128, 64, kernel_size=1)\n",
    "        self.dec2 = ResConvBlock3D(128, 64)  # 128 because 64 (up) + 64 (skip)\n",
    "\n",
    "        # Decoder 1\n",
    "        self.up_conv1 = nn.Conv3d(64, 32, kernel_size=1)\n",
    "        self.dec1 = ResConvBlock3D(64, 32)  # 64 because 32 (up) + 32 (skip)\n",
    "\n",
    "        self.final = nn.Conv3d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encoder\n",
    "        e1 = self.enc1(x)\n",
    "        e2 = self.enc2(self.pool1(e1))\n",
    "        e3 = self.enc3(self.pool2(e2))\n",
    "\n",
    "        # Bottleneck\n",
    "        b = self.bottleneck(self.pool3(e3))\n",
    "\n",
    "        # Decoder 3\n",
    "        d3 = F.interpolate(b, scale_factor=2, mode=\"trilinear\", align_corners=True)\n",
    "        d3 = self.up_conv3(d3)\n",
    "        d3 = torch.cat([d3, e3], dim=1)\n",
    "        d3 = self.dec3(d3)\n",
    "\n",
    "        # Decoder 2\n",
    "        d2 = F.interpolate(d3, scale_factor=2, mode=\"trilinear\", align_corners=True)\n",
    "        d2 = self.up_conv2(d2)\n",
    "        d2 = torch.cat([d2, e2], dim=1)\n",
    "        d2 = self.dec2(d2)\n",
    "\n",
    "        # Decoder 1\n",
    "        d1 = F.interpolate(d2, scale_factor=2, mode=\"trilinear\", align_corners=True)\n",
    "        d1 = self.up_conv1(d1)\n",
    "        d1 = torch.cat([d1, e1], dim=1)\n",
    "        d1 = self.dec1(d1)\n",
    "\n",
    "        return self.final(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c8d021e",
   "metadata": {},
   "source": [
    "## Training and Validation Setup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eabcaf43",
   "metadata": {},
   "source": [
    "### Metrics and Config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab88d78c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from monai.inferers.utils import sliding_window_inference\n",
    "from monai.metrics.regression import SSIMMetric, PSNRMetric\n",
    "from monai.losses.ssim_loss import SSIMLoss\n",
    "from pytorch_msssim import MS_SSIM\n",
    "\n",
    "# Initialize metrics\n",
    "# l1_criterion = torch.nn.L1Loss()\n",
    "# ssim_calc = SSIMMetric(spatial_dims=3)\n",
    "# psnr_calc = PSNRMetric(max_val=1.0)\n",
    "\n",
    "# ssim_criterion = SSIMLoss(spatial_dims=3)\n",
    "\n",
    "\n",
    "# Metrics & Loss\n",
    "class HybridLoss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.l1 = nn.L1Loss()\n",
    "        self.ssim = SSIMLoss(spatial_dims=3, data_range=1.0, win_size=11)\n",
    "        # self.ms_ssim_module = MS_SSIM(data_range=1.0, size_average=True, spatial_dims=3)\n",
    "\n",
    "    def forward(self, pred, target):\n",
    "        # ms_ssim_loss = 1 - self.ms_ssim_module(pred, target)\n",
    "        l1_loss = self.l1(pred, target)\n",
    "\n",
    "        # return 0.2 * l1_loss + 0.8 * ms_ssim_loss\n",
    "        ssim_loss = self.ssim(pred, target)\n",
    "        return 0.2 * l1_loss + 0.8 * ssim_loss\n",
    "\n",
    "\n",
    "ssim_metric = SSIMMetric(spatial_dims=3, data_range=1.0)\n",
    "# psnr_metric = PSNRMetric(max_val=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3756808",
   "metadata": {},
   "source": [
    "### Epoch Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9e0aaf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, loader, criterion, optimizer, scaler):\n",
    "    model.train()\n",
    "    ssim_metric.reset()\n",
    "    # psnr_metric.reset()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    pbar = tqdm(loader, desc=\"Train\")\n",
    "    for low, high in pbar:\n",
    "        low, high = low.to(CONFIG[\"DEVICE\"]), high.to(CONFIG[\"DEVICE\"])\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # with torch.amp.autocast(\"cuda\", enabled=(scaler is not None)):\n",
    "        with torch.autocast(\"cuda\", enabled=(scaler is not None)):\n",
    "            output = model(low)\n",
    "\n",
    "            # print(\n",
    "            #     f\"Pred min: {output.min().item():.4f} | Pred max: {output.max().item():.4f}\"\n",
    "            # )\n",
    "\n",
    "            # print(\n",
    "            #     f\"High min: {high.min().item():.4f} | High max: {high.max().item():.4f}\"\n",
    "            # )\n",
    "\n",
    "            # ---> ADD THIS LINE <---\n",
    "            # Forces all predictions into the [0, 1] range safely\n",
    "            output = torch.sigmoid(output)\n",
    "\n",
    "            # print(\n",
    "            #     f\"Sig(Pred) min: {output.min().item():.4f} | Sig(Pred) max: {output.max().item():.4f}\"\n",
    "            # )\n",
    "\n",
    "        output_f32 = output.float()\n",
    "        high_f32 = high.float()\n",
    "\n",
    "        loss = criterion(output, high)\n",
    "\n",
    "        if scaler:\n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            scaler.unscale_(optimizer)\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "        else:\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "\n",
    "        # Update Metrics\n",
    "        # ssim_metric(y_pred=output, y=high)\n",
    "        ssim_metric(y_pred=output_f32, y=high_f32)\n",
    "        # psnr_metric(y_pred=output, y=high)\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        pbar.set_postfix({\"running_loss\": f\"{running_loss:.4f}\"})\n",
    "\n",
    "    avg_ssim = ssim_metric.aggregate().item()\n",
    "    # avg_psnr = psnr_metric.aggregate().item()\n",
    "    avg_loss = running_loss / len(loader)\n",
    "\n",
    "    # combined = (0.5 * avg_ssim) + (0.5 * min(1.0, avg_psnr / 50.0))\n",
    "\n",
    "    return avg_ssim, avg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3245b36",
   "metadata": {},
   "source": [
    "### Epoch Validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6684564",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, loader, criterion):\n",
    "    model.eval()\n",
    "    # ssim_metric.reset()\n",
    "    # psnr_metric.reset()\n",
    "    running_loss = 0.0\n",
    "    all_slice_scores = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(loader, desc=\"Val\")\n",
    "        for low, high in pbar:\n",
    "            low, high = low.to(CONFIG[\"DEVICE\"]), high.to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "            # Sliding Window Inference for Full Volume Validation\n",
    "            output = sliding_window_inference(\n",
    "                inputs=low,\n",
    "                roi_size=CONFIG[\"PATCH_SIZE\"],\n",
    "                sw_batch_size=4,\n",
    "                predictor=model,\n",
    "                overlap=0.5,\n",
    "                mode=\"gaussian\",\n",
    "            )\n",
    "\n",
    "            # ---> ADD THIS LINE <---\n",
    "            output = torch.sigmoid(output)\n",
    "\n",
    "            loss = criterion(output, high)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # ssim_metric(y_pred=output, y=high)\n",
    "            # psnr_metric(y_pred=output, y=high)\n",
    "\n",
    "            # 2. Convert to NumPy and format for the Competition Metric\n",
    "            # Shape should become (179, 221, 200)\n",
    "            pred_vol = output.squeeze(1).cpu().numpy()\n",
    "            high_vol = high.squeeze(1).cpu().numpy()\n",
    "\n",
    "            # --- ADD THESE 3 LINES ---\n",
    "            # print(f\"\\nShape check: Pred {pred_vol.shape} | High {high_vol.shape}\")\n",
    "            # print(f\"Pre-clip Pred min/max: {pred_vol.min():.4f} / {pred_vol.max():.4f}\")\n",
    "            # print(f\"Pre-clip High min/max: {high_vol.min():.4f} / {high_vol.max():.4f}\")\n",
    "            # # -------------------------\n",
    "\n",
    "            # Clip predictions\n",
    "            pred_vol = np.clip(pred_vol, 0.0, 1.0)\n",
    "            high_vol = np.clip(high_vol, 0.0, 1.0)\n",
    "\n",
    "            # Clip predictions to [0, 1] as required by MS-SSIM\n",
    "            # pred_vol = np.clip(pred_vol, 0.0, 1.0)\n",
    "            # high_vol = np.clip(high_vol, 0.0, 1.0)\n",
    "\n",
    "            # 3. Slice-by-Slice 2D Evaluation (The Leaderboard Way)\n",
    "            for b in range(pred_vol.shape[0]):\n",
    "                # Loop over the Z (depth) dimension\n",
    "                for z in range(pred_vol.shape[3]):\n",
    "                    pred_slice = pred_vol[b, :, :, z]  # Now shape is strictly (96, 96)\n",
    "                    target_slice = high_vol[b, :, :, z]\n",
    "\n",
    "                    score = compute_ms_ssim(pred_slice, target_slice)\n",
    "                    all_slice_scores.append(score)\n",
    "\n",
    "        pbar.set_postfix(\n",
    "            {\"running_loss\": f\"{running_loss:.4f}\", \"last score\": f\"{score:.4f}\"}\n",
    "        )\n",
    "\n",
    "    # avg_ssim = ssim_metric.aggregate().item()\n",
    "    # avg_psnr = psnr_metric.aggregate().item()\n",
    "\n",
    "    avg_ms_ssim = np.mean(all_slice_scores)\n",
    "    avg_loss = running_loss / len(loader)\n",
    "\n",
    "    # # Leaderboard Formula\n",
    "    # combined = (0.5 * avg_ssim) + (0.5 * min(1.0, avg_psnr / 50.0))\n",
    "\n",
    "    return avg_ms_ssim, avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20d862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(\n",
    "    model,\n",
    "    loaders,\n",
    "    criterion,\n",
    "    optimizer,\n",
    "    scheduler,\n",
    "    num_epochs,\n",
    "    save_name=\"best_model.pt\",\n",
    "):\n",
    "    scaler = torch.GradScaler(\"cuda\") if CONFIG[\"DEVICE\"] == \"cuda\" else None\n",
    "    best_score = 0.0\n",
    "    history = {\"train_loss\": [], \"train_ssim\": [], \"val_loss\": [], \"val_ms_ssim\": []}\n",
    "\n",
    "    os.makedirs(CONFIG[\"PATHS\"][\"CHECKPOINT\"], exist_ok=True)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoch {epoch+1}/{num_epochs}\")\n",
    "\n",
    "        # Train\n",
    "        t_avg_ssim, t_avg_loss = train_one_epoch(\n",
    "            model, loaders[\"train\"], criterion, optimizer, scaler\n",
    "        )\n",
    "        print(\n",
    "            f\"Train   - Avg Loss: {t_avg_loss:.4f} | ** Avg ssim: {t_avg_ssim:.4f} **\"\n",
    "        )\n",
    "\n",
    "        # Validate\n",
    "        v_avg_ms_ssim, v_avg_loss = validate(model, loaders[\"val\"], criterion)\n",
    "        print(\n",
    "            f\"Val   - Avg Loss: {v_avg_loss:.4f} | ** Avg ms-ssim: {v_avg_ms_ssim:.4f} **\"\n",
    "        )\n",
    "\n",
    "        # Scheduler Step (Maximize Combined Score)\n",
    "        if isinstance(scheduler, torch.optim.lr_scheduler.ReduceLROnPlateau):\n",
    "            scheduler.step(v_avg_ms_ssim)\n",
    "        else:\n",
    "            scheduler.step()\n",
    "\n",
    "        # Save History\n",
    "        history[\"train_loss\"].append(t_avg_loss)\n",
    "        history[\"train_ssim\"].append(t_avg_ssim)\n",
    "        # history[\"train_score\"].append(t_score)\n",
    "        # history[\"train_ssim\"].append(t_ssim)\n",
    "        # history[\"train_psnr\"].append(t_psnr)\n",
    "\n",
    "        history[\"val_loss\"].append(v_avg_loss)\n",
    "        history[\"val_ms_ssim\"].append(v_avg_ms_ssim)\n",
    "        # history[\"val_ssim\"].append(v_ssim)\n",
    "        # history[\"val_psnr\"].append(v_psnr)\n",
    "\n",
    "        # Save Best Model\n",
    "        # if v_avg_ms_ssim > best_score:\n",
    "        #     best_score = v_avg_ms_ssim\n",
    "        #     torch.save(\n",
    "        #         model.state_dict(),\n",
    "        #         os.path.join(CONFIG[\"PATHS\"][\"CHECKPOINT\"], \"best_Unet_model.pt\"),\n",
    "        #     )\n",
    "        #     print(\">>> New Best Model Saved! <<<\")\n",
    "\n",
    "        if v_avg_ms_ssim > best_score:\n",
    "            best_score = v_avg_ms_ssim\n",
    "            torch.save(\n",
    "                model.state_dict(),\n",
    "                os.path.join(\n",
    "                    CONFIG[\"PATHS\"][\"CHECKPOINT\"], save_name\n",
    "                ),  # Use dynamic name\n",
    "            )\n",
    "            print(f\">>> New Best Model Saved as {save_name}! <<<\")\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc95953",
   "metadata": {},
   "source": [
    "## Train Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90074094",
   "metadata": {},
   "source": [
    "### Initialize Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464f15f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = UNet3D().to(CONFIG[\"DEVICE\"])\n",
    "model = BetterUNet3D().to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "criterion = HybridLoss()\n",
    "optimizer = torch.optim.AdamW(\n",
    "    model.parameters(), lr=CONFIG[\"LR\"], weight_decay=CONFIG[\"WEIGHT_DECAY\"]\n",
    ")\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, mode=\"max\", factor=0.5, patience=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ebf639",
   "metadata": {},
   "source": [
    "### Train Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d15dcd",
   "metadata": {},
   "source": [
    "### Single model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac8eef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from wakepy import keep\n",
    "\n",
    "# with keep.running():\n",
    "#     history = train_model(\n",
    "#         model, data_loaders, criterion, optimizer, scheduler, CONFIG[\"NUM_EPOCHS\"]\n",
    "#     )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a0f979",
   "metadata": {},
   "source": [
    "### Ensemble models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670c4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from wakepy import keep\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "\n",
    "# 1. Convert lists to numpy arrays so we can index them easily with KFold\n",
    "# We cap it at 18 just to be absolutely sure we match your sample limit\n",
    "all_low_paths = np.array(low_field_paths[:18])\n",
    "all_high_paths = np.array(high_field_paths[:18])\n",
    "\n",
    "# 2. Initialize 6-Fold CV\n",
    "n_splits = 6\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=CONFIG[\"SEED\"])\n",
    "\n",
    "# Dictionary to store the history of all folds for later analysis\n",
    "all_folds_history = {}\n",
    "\n",
    "print(f\"Starting {n_splits}-Fold Cross Validation on {len(all_low_paths)} samples...\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "with keep.running():\n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(all_low_paths)):\n",
    "        print(f\"\\nðŸš€ STARTING FOLD {fold + 1}/{n_splits}\")\n",
    "        print(f\"Train samples: {len(train_idx)} | Val samples: {len(val_idx)}\")\n",
    "\n",
    "        # 3. Create splits for this specific fold\n",
    "        fold_train_low = all_low_paths[train_idx].tolist()\n",
    "        fold_train_high = all_high_paths[train_idx].tolist()\n",
    "\n",
    "        fold_val_low = all_low_paths[val_idx].tolist()\n",
    "        fold_val_high = all_high_paths[val_idx].tolist()\n",
    "\n",
    "        # 4. Instantiate Datasets & Loaders\n",
    "        train_dataset = MRIPatchDataset(\n",
    "            fold_train_low, fold_train_high, transforms=train_transforms\n",
    "        )\n",
    "        val_dataset = MRIPatchDataset(fold_val_low, fold_val_high)\n",
    "\n",
    "        train_loader = DataLoader(\n",
    "            dataset=train_dataset,\n",
    "            batch_size=CONFIG[\"BATCH_SIZE\"],\n",
    "            shuffle=True,\n",
    "            pin_memory=True,\n",
    "            # num_workers=0,  # Increase num_workers if supported\n",
    "        )\n",
    "        val_loader = DataLoader(\n",
    "            dataset=val_dataset,\n",
    "            batch_size=CONFIG[\"BATCH_SIZE\"],\n",
    "            shuffle=False,\n",
    "            pin_memory=True,\n",
    "            # num_workers=0,\n",
    "        )\n",
    "\n",
    "        data_loaders = {\"train\": train_loader, \"val\": val_loader}\n",
    "\n",
    "        # 5. CRITICAL: Re-initialize the Model, Optimizer, and Scheduler FROM SCRATCH\n",
    "        # If you don't do this, Fold 2 will start with Fold 1's trained weights!\n",
    "        model = BetterUNet3D().to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "        # Join the directory and the filename into one path\n",
    "        checkpoint_path = os.path.join(\n",
    "            CONFIG[\"PATHS\"][\"CHECKPOINT\"], f\"best_model_fold_{fold + 1}.pt\"\n",
    "        )\n",
    "\n",
    "        model.load_state_dict(torch.load(checkpoint_path, weights_only=False))\n",
    "\n",
    "        criterion = HybridLoss()\n",
    "        optimizer = torch.optim.AdamW(\n",
    "            model.parameters(), lr=CONFIG[\"LR\"], weight_decay=CONFIG[\"WEIGHT_DECAY\"]\n",
    "        )\n",
    "        scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer, mode=\"max\", factor=0.5, patience=3\n",
    "        )\n",
    "\n",
    "        # 6. Train the Fold\n",
    "        save_filename = f\"best_model_fold_{fold + 1}_v2.pt\"\n",
    "\n",
    "        fold_history = train_model(\n",
    "            model=model,\n",
    "            loaders=data_loaders,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            num_epochs=CONFIG[\"NUM_EPOCHS\"],\n",
    "            save_name=save_filename,\n",
    "        )\n",
    "\n",
    "        # Save history\n",
    "        all_folds_history[f\"fold_{fold+1}\"] = fold_history\n",
    "        print(f\"âœ… Finished Fold {fold + 1}. Model saved as {save_filename}\\n\")\n",
    "\n",
    "        # 6. Memory Cleanup before next fold\n",
    "        # del (\n",
    "        #     model,\n",
    "        #     criterion,\n",
    "        #     optimizer,\n",
    "        #     scheduler,\n",
    "        #     fold_train_low,\n",
    "        #     fold_train_high,\n",
    "        #     fold_val_low,\n",
    "        #     fold_val_high,\n",
    "        #     train_dataset,\n",
    "        #     val_dataset,\n",
    "        #     train_loader,\n",
    "        #     val_loader,\n",
    "        #     data_loaders,\n",
    "        #     fold_history,\n",
    "        # )\n",
    "        # gc.collect()\n",
    "        # # 4. Clear the CUDA cache\n",
    "        # if torch.cuda.is_available():\n",
    "        #     torch.cuda.empty_cache()\n",
    "        # print(\n",
    "        #     f\"GPU Memory Freed: {torch.cuda.memory_reserved() / 1e9:.2f} GB remaining in cache\"\n",
    "        # )\n",
    "\n",
    "\n",
    "print(\"ðŸŽ‰ All 6 Folds Completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ef437",
   "metadata": {},
   "source": [
    "### Training Graphs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5971ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 4))\n",
    "\n",
    "# # --- Subplot 1: Loss ---\n",
    "# plt.subplot(1, 2, 1)\n",
    "# plt.plot(history[\"train_loss\"], label=\"Train Loss\")\n",
    "# plt.plot(history[\"val_loss\"], label=\"Val Loss\")\n",
    "# plt.legend()\n",
    "# plt.title(\"Loss\")\n",
    "\n",
    "# # # --- Subplot 2: SSIM  ---\n",
    "# # plt.subplot(1, 4, 2)\n",
    "# # plt.plot(history[\"train_ssim\"], label=\"Train SSIM\")\n",
    "# # plt.plot(history[\"val_ssim\"], label=\"Val SSIM\")\n",
    "# # plt.legend()\n",
    "# # plt.title(\"SSIM\")\n",
    "\n",
    "# # # --- Subplot 3: PSNR  ---\n",
    "# # plt.subplot(1, 4, 3)\n",
    "# # plt.plot(history[\"train_psnr\"], label=\"Train PSNR\")\n",
    "# # plt.plot(history[\"val_psnr\"], label=\"Val PSNR\")\n",
    "# # plt.legend()\n",
    "# # plt.title(\"PSNR\")\n",
    "\n",
    "# # # --- Subplot 4: Combined Score ---\n",
    "# # plt.subplot(1, 4, 4)\n",
    "# # plt.plot(history[\"train_score\"], label=\"Train Score\")\n",
    "# # plt.plot(history[\"val_score\"], label=\"Val Score\")\n",
    "# # plt.legend()\n",
    "# # plt.title(\"Score\")\n",
    "\n",
    "# # --- Subplot 5: Combined ms_ssim ---\n",
    "# plt.subplot(1, 2, 2)\n",
    "# plt.plot(history[\"train_ssim\"], label=\"Train ssim\")\n",
    "# plt.plot(history[\"val_ms_ssim\"], label=\"Val ms_ssim\")\n",
    "# plt.legend()\n",
    "# plt.title(\"(ms-)ssim\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "\n",
    "\n",
    "# plt.savefig(os.path.join(CONFIG[\"PATHS\"][\"CHECKPOINT\"], \"training_curves.png\"))\n",
    "# print(\n",
    "#     f\"Train/Val curves saved to {os.path.join(CONFIG['PATHS']['CHECKPOINT'], 'training_curves.png')}\"\n",
    "# )\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89bb287",
   "metadata": {},
   "source": [
    "## Testing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71f8421",
   "metadata": {},
   "source": [
    "### Single model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b8ebbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # trained_model = UNet3D().to(CONFIG[\"DEVICE\"])\n",
    "# trained_model = BetterUNet3D().to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "# # Join the directory and the filename into one path\n",
    "# checkpoint_path = os.path.join(CONFIG[\"PATHS\"][\"CHECKPOINT\"], \"best_Unet_model.pt\")\n",
    "\n",
    "\n",
    "# trained_model.load_state_dict(torch.load(checkpoint_path, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04aeee06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# from tqdm import tqdm\n",
    "# from monai.inferers import sliding_window_inference\n",
    "# import nibabel as nib\n",
    "\n",
    "# test_samples = [\"sample_019\", \"sample_020\", \"sample_021\", \"sample_022\", \"sample_023\"]\n",
    "# predictions = {}\n",
    "\n",
    "# trained_model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for sample_id in tqdm(test_samples, desc=\"Test\"):\n",
    "#         # print(f\"Processing {sample_id}...\")\n",
    "#         low_path = f\"test/low_field/{sample_id}_lowfield.nii\"\n",
    "\n",
    "#         # 1. Use your Resizer to get the FULL volume [1, 179, 221, 200]\n",
    "#         full_vol, _ = prepare_input(low_path)\n",
    "\n",
    "#         # 2. Normalize and add batch dimension -> [1, 1, 179, 221, 200]\n",
    "#         test_input = normalize_tensor(full_vol).to(CONFIG[\"DEVICE\"]).unsqueeze(0)\n",
    "\n",
    "#         # 3. Sliding window handles the patching/stitching AUTOMATICALLY\n",
    "#         output = sliding_window_inference(\n",
    "#             inputs=test_input,\n",
    "#             roi_size=CONFIG[\"PATCH_SIZE\"],\n",
    "#             sw_batch_size=4,\n",
    "#             predictor=trained_model,\n",
    "#             overlap=0.5,\n",
    "#             mode=\"gaussian\",  # This removes the grid lines!\n",
    "#         )\n",
    "\n",
    "#         # ---> ADDED: APPLY SIGMOID <---\n",
    "#         # Forces the stitched volume strictly into the [0.0, 1.0] range\n",
    "\n",
    "#         output = torch.sigmoid(output)\n",
    "\n",
    "#         # 4. Remove extra dimensions to get (179, 221, 200)\n",
    "#         pred_volume = output.squeeze().cpu().numpy()\n",
    "\n",
    "#         # ---> ADDED: CLIP VALUES <---\n",
    "#         # Absolute guarantee no floating point errors sneak past 1.0 or below 0.0\n",
    "#         pred_volume = np.clip(pred_volume, 0.0, 1.0)\n",
    "\n",
    "#         # display_nifti(pred_volume)\n",
    "\n",
    "#         # print(f\"Final Prediction Shape: {pred_volume.shape}\") # Should be (179, 221, 200)\n",
    "#         predictions[sample_id] = pred_volume\n",
    "\n",
    "# # 5. Create Submission File\n",
    "# submission_df = create_submission_df(predictions)\n",
    "# submission_df.to_csv(\"submission.csv\", index=False)\n",
    "# print(\"Submission saved to submission.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7821d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # 1. Get the first test sample results\n",
    "# for sample_id in test_samples:\n",
    "#     pred_volume = predictions[sample_id]  # Shape (179, 221, 200)\n",
    "\n",
    "#     # 2. Get the original upsampled input for comparison\n",
    "#     low_path = f\"test/low_field/{sample_id}_lowfield.nii\"\n",
    "#     input_tensor, _ = prepare_input(low_path)\n",
    "#     input_tensor = normalize_tensor(input_tensor)\n",
    "\n",
    "#     input_volume = input_tensor.squeeze().cpu().numpy()  # Shape (179, 221, 200)\n",
    "\n",
    "#     # 3. Select a middle axial slice (Index 100)\n",
    "#     slice_idx = 100\n",
    "\n",
    "#     plt.figure(figsize=(12, 6))\n",
    "\n",
    "#     # Subplot 1: Input (Bicubic/Trilinear Upsampled)\n",
    "#     plt.subplot(1, 2, 1)\n",
    "#     plt.imshow(input_volume[:, :, slice_idx].T, cmap=\"gray\", origin=\"lower\")\n",
    "#     plt.title(f\"Upsampled Low-Field (Input)\\n{sample_id} - Slice {slice_idx}\")\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     # Subplot 2: Model Prediction (Enhanced)\n",
    "#     plt.subplot(1, 2, 2)\n",
    "#     plt.imshow(pred_volume[:, :, slice_idx].T, cmap=\"gray\", origin=\"lower\")\n",
    "#     plt.title(f\"Model Enhancement (Prediction)\\n{sample_id} - Slice {slice_idx}\")\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239451a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test_samples = [\"sample_019\", \"sample_020\", \"sample_021\", \"sample_022\", \"sample_023\"]\n",
    "# train_samples = [\"sample_001\", \"sample_002\", \"sample_003\"]\n",
    "# predictions = {}\n",
    "\n",
    "# trained_model.eval()\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for sample_id in tqdm(train_samples, desc=\"Test\"):\n",
    "#         # print(f\"Processing {sample_id}...\")\n",
    "#         # low_path = f\"test/low_field/{sample_id}_lowfield.nii\"\n",
    "#         low_path = f\"train/low_field/{sample_id}_lowfield.nii\"\n",
    "\n",
    "#         # 1. Use your Resizer to get the FULL volume [1, 179, 221, 200]\n",
    "#         full_vol, _ = prepare_input(low_path)\n",
    "\n",
    "#         # 2. Normalize and add batch dimension -> [1, 1, 179, 221, 200]\n",
    "#         test_input = normalize_tensor(full_vol).to(CONFIG[\"DEVICE\"]).unsqueeze(0)\n",
    "\n",
    "#         # 3. Sliding window handles the patching/stitching AUTOMATICALLY\n",
    "#         output = sliding_window_inference(\n",
    "#             inputs=test_input,\n",
    "#             roi_size=CONFIG[\"PATCH_SIZE\"],\n",
    "#             sw_batch_size=4,\n",
    "#             predictor=trained_model,\n",
    "#             overlap=0.5,\n",
    "#             mode=\"gaussian\",  # This removes the grid lines!\n",
    "#         )\n",
    "\n",
    "#         output = torch.sigmoid(output)\n",
    "#         pred_volume = output.squeeze().cpu().numpy()\n",
    "#         pred_volume = np.clip(pred_volume, 0.0, 1.0)\n",
    "\n",
    "#         # print(f\"Final Prediction Shape: {pred_volume.shape}\") # Should be (179, 221, 200)\n",
    "#         predictions[sample_id] = pred_volume\n",
    "\n",
    "\n",
    "# # 1. Get the first test sample results\n",
    "# sample_id = \"sample_002\"\n",
    "# pred_volume = predictions[sample_id]  # Shape (179, 221, 200)\n",
    "\n",
    "# # 2. Get the original upsampled input for comparison\n",
    "# low_path = f\"train/low_field/{sample_id}_lowfield.nii\"\n",
    "# high_path = f\"train/high_field/{sample_id}_highfield.nii\"\n",
    "\n",
    "# high_volume = load_nifti(high_path)\n",
    "\n",
    "# input_tensor, _ = prepare_input(low_path, high_volume.shape)\n",
    "# input_tensor = normalize_tensor(input_tensor)\n",
    "\n",
    "# input_volume = input_tensor.squeeze().cpu().numpy()  # Shape (179, 221, 200)\n",
    "\n",
    "# # 3. Select a middle axial slice (Index 100)\n",
    "# slice_idx = 100\n",
    "\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# # Subplot 1: Input (Bicubic/Trilinear Upsampled)\n",
    "# plt.subplot(1, 3, 1)\n",
    "# plt.imshow(input_volume[:, :, slice_idx].T, cmap=\"gray\", origin=\"lower\")\n",
    "# plt.title(f\"Upsampled Low-Field (Input)\\n{sample_id} - Slice {slice_idx}\")\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# # Subplot 2: Model Prediction (Enhanced)\n",
    "# plt.subplot(1, 3, 2)\n",
    "# plt.imshow(pred_volume[:, :, slice_idx].T, cmap=\"gray\", origin=\"lower\")\n",
    "# plt.title(f\"Model Enhancement (Prediction)\\n{sample_id} - Slice {slice_idx}\")\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# # Subplot 3: Model Prediction (Enhanced)\n",
    "# plt.subplot(1, 3, 3)\n",
    "# plt.imshow(high_volume[:, :, slice_idx].T, cmap=\"gray\", origin=\"lower\")\n",
    "# plt.title(f\"High-Field (Target)\\n{sample_id} - Slice {slice_idx}\")\n",
    "# plt.axis(\"off\")\n",
    "\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68da01c",
   "metadata": {},
   "source": [
    "### K-fold ensemble\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4a438d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "\n",
    "def load_ensemble_models(checkpoint_dir, n_splits=6):\n",
    "    \"\"\"Loads all k-fold models into memory.\"\"\"\n",
    "    models = []\n",
    "    print(f\"Loading {n_splits} models from {checkpoint_dir}...\")\n",
    "\n",
    "    for i in range(1, n_splits + 1):\n",
    "        model_path = os.path.join(checkpoint_dir, f\"best_model_fold_{i}.pt\")\n",
    "\n",
    "        # Initialize the architecture\n",
    "        model = BetterUNet3D().to(CONFIG[\"DEVICE\"])\n",
    "\n",
    "        # Load weights\n",
    "        model.load_state_dict(torch.load(model_path, weights_only=True))\n",
    "        model.eval()  # Set to evaluation mode\n",
    "\n",
    "        models.append(model)\n",
    "        print(f\"  -> Loaded fold {i}\")\n",
    "\n",
    "    return models\n",
    "\n",
    "\n",
    "def ensemble_predict_and_save(\n",
    "    models, test_dir, output_dir, target_shape=(179, 221, 200)\n",
    "):\n",
    "    \"\"\"Runs sliding window inference across all models and saves the averaged NIfTI.\"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Get all test low-field NIfTI files\n",
    "    test_paths = glob.glob(os.path.join(test_dir, \"*_lowfield.nii*\"))\n",
    "\n",
    "    if len(test_paths) == 0:\n",
    "        print(f\"No test files found in {test_dir}\")\n",
    "        return\n",
    "\n",
    "    print(f\"\\nStarting ensemble inference on {len(test_paths)} test files...\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for l_path in tqdm(test_paths, desc=\"Predicting Test Set\"):\n",
    "            # 1. Load, Upsample, and Normalize Input\n",
    "            low_vol, original_affine = prepare_input(l_path, target_shape=target_shape)\n",
    "\n",
    "            # Keep original shape for affine math later\n",
    "            low_nifti_shape = nib.load(l_path).shape\n",
    "\n",
    "            low_tensor = (\n",
    "                normalize_tensor(low_vol).unsqueeze(0).to(CONFIG[\"DEVICE\"])\n",
    "            )  # Add batch dim -> (1, 1, D, H, W)\n",
    "\n",
    "            # 2. Run Inference for all 6 models\n",
    "            ensemble_preds = []\n",
    "            for model in models:\n",
    "                # Sliding window inference is memory efficient for large 3D volumes\n",
    "                pred = sliding_window_inference(\n",
    "                    inputs=low_tensor,\n",
    "                    roi_size=CONFIG[\"PATCH_SIZE\"],\n",
    "                    sw_batch_size=4,\n",
    "                    predictor=model,\n",
    "                    overlap=0.5,\n",
    "                    mode=\"gaussian\",\n",
    "                )\n",
    "\n",
    "                pred = torch.sigmoid(pred)\n",
    "                # Apply clamp instead of sigmoid (as discussed previously)\n",
    "                pred = torch.clamp(pred, min=0.0, max=1.0)\n",
    "                ensemble_preds.append(pred)\n",
    "\n",
    "            # 3. Average the predictions (Ensemble)\n",
    "            # Stack along a new dimension and take the mean\n",
    "            stacked_preds = torch.stack(ensemble_preds, dim=0)\n",
    "            avg_pred = torch.mean(stacked_preds, dim=0)\n",
    "\n",
    "            # 4. Convert back to numpy array (H, W, D)\n",
    "            # Squeeze out Batch and Channel dims: (1, 1, H, W, D) -> (H, W, D)\n",
    "            final_vol = avg_pred.squeeze().cpu().numpy()\n",
    "\n",
    "            # 5. Fix the Affine Matrix for High-Resolution\n",
    "            # We must scale the voxel spacing so the NIfTI header knows it's higher resolution\n",
    "            scale_factors = np.array(low_nifti_shape) / np.array(final_vol.shape)\n",
    "            new_affine = original_affine.copy()\n",
    "            new_affine[:3, :3] = original_affine[:3, :3] * scale_factors\n",
    "\n",
    "            # 6. Save the final NIfTI file\n",
    "            filename = os.path.basename(l_path).replace(\n",
    "                \"_lowfield.nii\", \"_highfield_pred.nii\"\n",
    "            )\n",
    "            output_path = os.path.join(output_dir, filename)\n",
    "\n",
    "            out_img = nib.Nifti1Image(final_vol, new_affine)\n",
    "            nib.save(out_img, output_path)\n",
    "\n",
    "\n",
    "# --- Execute the Pipeline ---\n",
    "# 1. Load the 6 trained models\n",
    "ensemble = load_ensemble_models(CONFIG[\"PATHS\"][\"CHECKPOINT\"])\n",
    "\n",
    "# 2. Run predictions and save to a new 'submission_niftis' folder\n",
    "OUTPUT_DIR = os.path.join(PROJECT_DIR, \"submission_niftis\")\n",
    "ensemble_predict_and_save(models=ensemble, test_dir=LF_TEST, output_dir=OUTPUT_DIR)\n",
    "\n",
    "print(f\"\\nâœ… All predictions saved to: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c170b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import os\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def create_submission_csv(predictions_dir, output_csv_name=\"submission.csv\"):\n",
    "    \"\"\"\n",
    "    Reads all predicted NIfTI files, flattens their 3D arrays,\n",
    "    and packages them into a competition-ready CSV.\n",
    "    \"\"\"\n",
    "    print(f\"Scanning {predictions_dir} for predicted volumes...\")\n",
    "    pred_paths = glob.glob(os.path.join(predictions_dir, \"*_highfield_pred.nii*\"))\n",
    "\n",
    "    if not pred_paths:\n",
    "        raise FileNotFoundError(\"No predicted NIfTI files found! Check your directory.\")\n",
    "\n",
    "    submission_rows = pd.DataFrame(columns=[\"row_id\", \"prediction\"])\n",
    "\n",
    "    # Process each predicted MRI\n",
    "    for path in tqdm(pred_paths, desc=\"Converting NIfTIs to CSV format\"):\n",
    "        # 1. Extract a clean ID from the filename (e.g., \"subject_05\")\n",
    "        base_name = os.path.basename(path)\n",
    "        subject_id = base_name.replace(\"_highfield_pred.nii\", \"\").replace(\".gz\", \"\")\n",
    "\n",
    "        # print(path)\n",
    "\n",
    "        # 4. Convert the array to a space-separated string\n",
    "        # Warning: This step can be RAM intensive for large batches\n",
    "\n",
    "        new_df = pd.DataFrame(nifti_to_submission_rows(path, subject_id))\n",
    "\n",
    "        # print(new_df)\n",
    "\n",
    "        # print(new_row[0])\n",
    "\n",
    "        # new_row_series = pd.Series(new_row, index=submission_rows.columns)\n",
    "\n",
    "        # 5. Append to our list of rows\n",
    "        submission_rows = pd.concat([submission_rows, new_df], ignore_index=True)\n",
    "\n",
    "    # Convert to a Pandas DataFrame and save\n",
    "    print(\"\\nCompiling DataFrame and saving to CSV... (This might take a minute)\")\n",
    "    df = pd.DataFrame(submission_rows)\n",
    "\n",
    "    # print(df)\n",
    "    # Save without the pandas index column\n",
    "    df.to_csv(output_csv_name, index=False)\n",
    "    print(f\"âœ… Success! Submission saved as {output_csv_name}\")\n",
    "\n",
    "\n",
    "# --- Execute the Script ---\n",
    "# Ensure this matches the OUTPUT_DIR from the previous step\n",
    "PREDICTIONS_FOLDER = os.path.join(PROJECT_DIR, \"submission_niftis\")\n",
    "FINAL_CSV_PATH = os.path.join(PROJECT_DIR, \"submission_ensemble.csv\")\n",
    "\n",
    "create_submission_csv(\n",
    "    predictions_dir=PREDICTIONS_FOLDER, output_csv_name=FINAL_CSV_PATH\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroinfo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
